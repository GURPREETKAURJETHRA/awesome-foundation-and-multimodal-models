<h1 align="center">awesome foundation and multimodal models</h1>

## üëã hello

**foundation model** - a pre-trained machine learning model that serves as a base for a wide range of downstream tasks. It captures general knowledge from a large dataset and can be fine-tuned to perform specific tasks more effectively.

**multimodal model** - a model that can process multiple modalities (e.g. text, image,
video, audio, etc.) at the same time.

## üóûÔ∏è papers

<!--- AUTOGENERATED_COURSES_TABLE -->
<!---
   WARNING: DO NOT EDIT THIS TABLE MANUALLY. IT IS AUTOMATICALLY GENERATED.
   HEAD OVER TO CONTRIBUTING.MD FOR MORE DETAILS ON HOW TO MAKE CHANGES PROPERLY.
-->
| **title** | **date** | **repository / paper** |
|:---------:|:--------:|:----------------------:|
| LLaVA: Large Language and Vision Assistant | 17-04-2023 | [![GitHub](https://img.shields.io/github/stars/haotian-liu/LLaVA?style=social)](https://github.com/haotian-liu/LLaVA) [![arXiv](https://img.shields.io/badge/arXiv-2304.08485-b31b1b.svg)](https://arxiv.org/abs/2304.08485)|
<!--- AUTOGENERATED_COURSES_TABLE -->

## ü¶∏ contribution

We would love your help in making this repository even better! If you know of an
amazing paper that isn't listed here, or if you have any suggestions for improvement,
feel free to open an [issue](https://github.com/SkalskiP/awesome-foundation-and-multimodal-models/issues)
or submit a [pull request](https://github.com/SkalskiP/awesome-foundation-and-multimodal-models/pulls).
